{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4855, 4397)\n"
     ]
    }
   ],
   "source": [
    "# Load an example image\n",
    "img_path = '/Users/kamillaraki/Downloads/CROPPED-AMA/1-112-PR-PID-009_2_3.jpg'\n",
    "img = Image.open(img_path)\n",
    "\n",
    "# Check the size of the image\n",
    "print(img.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1792, 1792)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_path = '/Users/kamillaraki/Downloads/CROPPED-AMA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_path = '/Users/kamillaraki/Downloads/TEST1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, rotation_range=0, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, horizontal_flip=True, fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/Users/kamillaraki/Downloads/CROPPED-AMA'):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "        # Load the image using PIL\n",
    "        img = Image.open(os.path.join('/Users/kamillaraki/Downloads/CROPPED-AMA', filename))\n",
    "\n",
    "        # Resize the image to the desired input shape\n",
    "        img_resized = img.resize(input_shape)\n",
    "\n",
    "        # Save the resized image to the output folder\n",
    "        new_filename = filename.split('.')[0] + '_resized.jpg'  # Change the filename as desired\n",
    "        img_resized.save(os.path.join('/Users/kamillaraki/Downloads/TEST1', new_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_path = '/Users/kamillaraki/Downloads/CROPPED-UNLAB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_path = '/Users/kamillaraki/Downloads/TEST3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, rotation_range=0, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1, horizontal_flip=True, fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/Users/kamillaraki/Downloads/CROPPED-UNLAB'):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "        # Load the image using PIL\n",
    "        img = Image.open(os.path.join('/Users/kamillaraki/Downloads/CROPPED-UNLAB', filename))\n",
    "\n",
    "        # Resize the image to the desired input shape\n",
    "        img_resized = img.resize(input_shape)\n",
    "\n",
    "        # Save the resized image to the output folder\n",
    "        new_filename = filename.split('.')[0] + '_resized.jpg'  # Change the filename as desired\n",
    "        img_resized.save(os.path.join('/Users/kamillaraki/Downloads/TEST3', new_filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape for your images\n",
    "input_shape = (1792, 1792, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size and number of epochs for training\n",
    "batch_size = 8\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset directory\n",
    "train_data_dir = '/Users/kamillaraki/Downloads/SAMY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your labeled dataset for functional P&IDs\n",
    "train_data_dir_func = '/Users/kamillaraki/Downloads/SAMY/TEST1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your labeled dataset for dysfunctional P&IDs\n",
    "train_data_dir_dysfunc = '/Users/kamillaraki/Downloads/SAMY/TEST2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your unlabeled dataset\n",
    "test_data_dir = '/Users/kamillaraki/Downloads/SAMY/TESTT3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained VGG16 model without the top layers\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the pre-trained layers to prevent them from being updated during training\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new layers to the pre-trained model for your specific problem\n",
    "model = Sequential()\n",
    "model.add(vgg_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with an appropriate loss function, optimizer, and metrics\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 images belonging to 2 classes.\n",
      "Found 7 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the data generators for training, validation, and testing\n",
    "train_data_gen_func = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_data_gen_dysfunc = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_data_gen_func.flow_from_directory(train_data_dir, target_size=input_shape[:2], batch_size=batch_size, class_mode='binary', subset='training')\n",
    "validation_generator = train_data_gen_func.flow_from_directory(train_data_dir, target_size=input_shape[:2], batch_size=batch_size, class_mode='binary', subset='validation')\n",
    "test_generator = test_data_gen.flow_from_directory(test_data_dir, target_size=input_shape[:2], batch_size=batch_size, class_mode=None, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 446s 153s/step - loss: 127.0304 - accuracy: 0.4583\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 429s 144s/step - loss: 106.3036 - accuracy: 0.6250\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 374s 111s/step - loss: 76.0322 - accuracy: 0.6667\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 371s 115s/step - loss: 48.8636 - accuracy: 0.8571\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 405s 131s/step - loss: 36.5002 - accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 408s 133s/step - loss: 6.0778 - accuracy: 0.9583\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 380s 146s/step - loss: 60.7290 - accuracy: 0.8571\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 425s 138s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 422s 136s/step - loss: 1.8675e-13 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 349s 109s/step - loss: 53.4590 - accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_generator, steps_per_epoch=train_generator.n//batch_size, epochs=num_epochs, validation_data=validation_generator, validation_steps=validation_generator.n//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('SAMY_VGG16.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the results on unlabeled dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(test_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.DataFrame({'TESTT3': test_filenames, 'label': None})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_data_gen.flow_from_dataframe(test_df, test_data_dir, x_col='TESTT3', y_col='label', target_size=input_shape[:2], batch_size=batch_size, class_mode=None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-207e94278253>:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  preds = model.predict_generator(test_generator, steps=test_generator.n//batch_size, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 230s 113s/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_generator(test_generator, steps=test_generator.n//batch_size, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-112-PR-PID-005_1_3_resized.jpg functional\n",
      "1-112-PR-PID-014_1_3_resized.jpg functional\n",
      "9049679-120-13-PID Rev-01_resized.jpg dysfunctional\n",
      "1-110-PR-PID-011_2_3_resized.jpg functional\n",
      "9049679-120-14-PID Rev-01_resized.jpg functional\n",
      "1-112-PR-PID-015_1_3_resized.jpg functional\n",
      "9049679-120-15-PID Rev-01_resized.jpg dysfunctional\n",
      "9049679-120-12-PID Rev-01_resized.jpg functional\n",
      "1-110-PR-PID-001_2_3_resized.jpg functional\n",
      "1-112-PR-PID-004_1_3_resized.jpg functional\n",
      "9049679-120-09-PID Rev-01_resized.jpg dysfunctional\n",
      "1-112-PR-PID-006_1_3_resized.jpg functional\n",
      "1-110-PR-PID-003_2_3_resized.jpg functional\n",
      "9049679-120-07-PID Rev-01_resized.jpg functional\n",
      "9049679-120-16-PID-Rev-02_resized.jpg dysfunctional\n",
      "1-110-PR-PID-002_2_3_resized.jpg functional\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] >= threshold:\n",
    "        print(test_generator.filenames[i], \"dysfunctional\")\n",
    "    else:\n",
    "        print(test_generator.filenames[i], \"functional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
